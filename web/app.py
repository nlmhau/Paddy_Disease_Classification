import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from PIL import Image
import matplotlib.cm as cm
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Cho ph√©p ch·∫°y `streamlit run web/app.py` m√† kh√¥ng c·∫ßn bi·∫øn `src/` th√†nh package.
ROOT_DIR = Path(__file__).resolve().parents[1]
SRC_DIR = ROOT_DIR / "src"
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from preprocessing import (
    LABEL_MAP,
    add_image_path_column,
    build_image_generators,
    default_data_paths,
    load_train_df,
    split_train_val,
)


APP_TITLE = "H·ªá th·ªëng ph√¢n lo·∫°i b·ªánh l√° l√∫a"
DEFAULT_MODEL_PATHS = [
    "monster_cnn_best.keras",
    "src/monster_cnn_best.keras",
    "data/monster_cnn_best.keras",
]


@st.cache_data(show_spinner=False)
def discover_keras_models() -> List[str]:
    """T·ª± ƒë·ªông qu√©t c√°c file *.keras trong project ƒë·ªÉ ng∆∞·ªùi d√πng ch·ªçn."""

    models: List[str] = []
    try:
        for p in ROOT_DIR.rglob("*.keras"):
            if p.is_file():
                models.append(str(p.relative_to(ROOT_DIR)))
    except Exception:
        models = []

    def sort_key(x: str) -> Tuple[int, str]:
        return (0 if os.path.basename(x).lower() == "monster_cnn_best.keras" else 1, x.lower())

    models = sorted(set(models), key=sort_key)

    # Gi·ªØ m·ªôt v√†i g·ª£i √Ω m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c.
    if not models:
        models = DEFAULT_MODEL_PATHS.copy()

    return models


def model_picker(label: str) -> str:
    """UI ch·ªçn model: dropdown c√°c file .keras + √¥ nh·∫≠p tu·ª≥ ch·ªçn."""

    models = discover_keras_models()
    default_idx = 0
    for i, p in enumerate(models):
        if os.path.basename(p).lower() == "monster_cnn_best.keras":
            default_idx = i
            break

    selected = st.selectbox(label, models, index=default_idx)
    custom = st.text_input("Ho·∫∑c nh·∫≠p ƒë∆∞·ªùng d·∫´n model (.keras) kh√°c", value="")
    return custom.strip() if custom.strip() else selected


def _resolve_model_path(candidate: str) -> str | None:
    p = Path(candidate)
    if p.exists() and p.is_file():
        return str(p)
    return None


@st.cache_data(show_spinner=False)
def load_dataframe() -> pd.DataFrame:
    paths = default_data_paths()
    df = load_train_df(paths.train_csv, label_map=LABEL_MAP)
    df = add_image_path_column(df, paths.train_img_dir)
    return df


@st.cache_resource(show_spinner=False)
def get_class_indices(img_size: Tuple[int, int], batch_size: int) -> Dict[str, int]:
    df = load_dataframe()
    train_df, val_df = split_train_val(df, test_size=0.2, random_state=42)
    make_generators = build_image_generators(img_size=img_size, batch_size=batch_size)
    train_generator, _ = make_generators(train_df, val_df)
    return train_generator.class_indices


@st.cache_resource(show_spinner=False)
def load_tf_model(model_path: str, model_mtime: float | None = None):
    import tensorflow as tf

    if model_mtime is None:
        try:
            model_mtime = os.path.getmtime(model_path)
        except OSError:
            model_mtime = None

    # Try TensorFlow/Keras loader first.
    try:
        return tf.keras.models.load_model(model_path)
    except Exception:
        pass

    # Compatibility: some older models include Dense config with `quantization_config` which
    # newer/older Keras may not accept. Patch Dense to ignore this kwarg.
    try:
        from tensorflow.keras.layers import Dense as TfDense

        class PatchedDense(TfDense):
            def __init__(self, *args, **kwargs):
                kwargs.pop("quantization_config", None)
                super().__init__(*args, **kwargs)

        return tf.keras.models.load_model(
            model_path,
            compile=False,
            custom_objects={"Dense": PatchedDense},
        )
    except Exception:
        pass

    # Fallback for mismatched TF/Keras versions: avoid deserialization issues.
    try:
        return tf.keras.models.load_model(model_path, compile=False)
    except Exception:
        pass

    # Keras 3: safe_mode can block loading some older configs.
    try:
        return tf.keras.models.load_model(model_path, compile=False, safe_mode=False)
    except TypeError:
        # safe_mode not supported in this TF/Keras version.
        pass
    except Exception:
        pass

    # If the model was saved with standalone Keras (keras==3), tf.keras loader may fail.
    try:
        import keras
    except Exception as e:
        raise RuntimeError(
            "Kh√¥ng th·ªÉ load model b·∫±ng tf.keras (c√≥ th·ªÉ l·ªách version save/load). ƒê·ªìng th·ªùi kh√¥ng import ƒë∆∞·ª£c package 'keras'."
        ) from e

    def _keras_load_with_patched_dense(*, safe_mode: bool | None):
        from keras.layers import Dense as KDense

        class PatchedDenseKeras(KDense):
            def __init__(self, *args, **kwargs):
                kwargs.pop("quantization_config", None)
                super().__init__(*args, **kwargs)

        import keras.layers as _kl
        import keras

        try:
            from keras.utils import get_custom_objects as _get_custom_objects
        except Exception:
            _get_custom_objects = None

        # Keras deserialization often resolves the class from internal module path
        # `keras.src.layers.core.dense.Dense`, so we patch both aliases.
        try:
            import keras.src.layers.core.dense as _kd
        except Exception:
            _kd = None

        orig_dense = getattr(_kl, "Dense", None)
        _kl.Dense = PatchedDenseKeras
        orig_dense_src = getattr(_kd, "Dense", None) if _kd is not None else None
        if _kd is not None:
            _kd.Dense = PatchedDenseKeras

        # Also patch Keras global custom object registry, which is another resolution path
        # used during deserialization.
        orig_custom_dense = None
        orig_custom_keras_layers_dense = None
        orig_custom_keras_src_dense = None
        if _get_custom_objects is not None:
            custom = _get_custom_objects()
            orig_custom_dense = custom.get("Dense")
            orig_custom_keras_layers_dense = custom.get("keras.layers.Dense")
            orig_custom_keras_src_dense = custom.get("keras.src.layers.core.dense.Dense")
            custom["Dense"] = PatchedDenseKeras
            custom["keras.layers.Dense"] = PatchedDenseKeras
            custom["keras.src.layers.core.dense.Dense"] = PatchedDenseKeras
        try:
            if safe_mode is None:
                return keras.models.load_model(model_path, compile=False)
            return keras.models.load_model(model_path, compile=False, safe_mode=safe_mode)
        finally:
            if orig_dense is not None:
                _kl.Dense = orig_dense
            if _kd is not None and orig_dense_src is not None:
                _kd.Dense = orig_dense_src
            if _get_custom_objects is not None:
                custom = _get_custom_objects()
                if orig_custom_dense is None:
                    custom.pop("Dense", None)
                else:
                    custom["Dense"] = orig_custom_dense
                if orig_custom_keras_layers_dense is None:
                    custom.pop("keras.layers.Dense", None)
                else:
                    custom["keras.layers.Dense"] = orig_custom_keras_layers_dense
                if orig_custom_keras_src_dense is None:
                    custom.pop("keras.src.layers.core.dense.Dense", None)
                else:
                    custom["keras.src.layers.core.dense.Dense"] = orig_custom_keras_src_dense

    try:
        return keras.models.load_model(model_path)
    except Exception:
        pass

    try:
        return _keras_load_with_patched_dense(safe_mode=None)
    except Exception:
        pass

    try:
        return _keras_load_with_patched_dense(safe_mode=False)
    except TypeError:
        return _keras_load_with_patched_dense(safe_mode=None)


def predict_pil_image(model, img_pil: Image.Image, img_size: Tuple[int, int], idx_to_class: Dict[int, str], model_path: str | None = None) -> pd.DataFrame:
    img = img_pil.convert("RGB").resize(img_size)
    img_arr = np.array(img, dtype=np.float32)

    # Ch·ªçn preprocessing ph√π h·ª£p v·ªõi model
    if model_path:
        name = os.path.basename(model_path).lower()
        if "efficientnetb1" in name or "efnet_b1" in name:
            from tensorflow.keras.applications.efficientnet import preprocess_input
            img_arr = preprocess_input(img_arr)
        elif "efficientnetv2" in name or "efnetv2" in name:
            from tensorflow.keras.applications.efficientnet_v2 import preprocess_input
            img_arr = preprocess_input(img_arr)
        else:
            img_arr = img_arr / 255.0
    else:
        img_arr = img_arr / 255.0

    img_arr = np.expand_dims(img_arr, axis=0)

    preds = model.predict(img_arr, verbose=0)[0]
    df_prob = pd.DataFrame(
        {
            "Lo·∫°i b·ªánh": [idx_to_class[i] for i in range(len(preds))],
            "X√°c su·∫•t (%)": preds * 100,
        }
    ).sort_values("X√°c su·∫•t (%)", ascending=False)

    return df_prob


def _iter_layers_recursive(model):
    import tensorflow as tf

    for layer in getattr(model, "layers", []):
        yield layer
        if isinstance(layer, tf.keras.Model):
            yield from _iter_layers_recursive(layer)


def _find_last_conv_layer_name(model) -> str | None:
    import tensorflow as tf

    conv_layers = []
    for layer in _iter_layers_recursive(model):
        if isinstance(layer, tf.keras.layers.Conv2D):
            conv_layers.append(layer)
    if not conv_layers:
        return None
    return conv_layers[-1].name


def grad_cam_heatmap(model, img_array: np.ndarray, layer_name: str | None = None) -> np.ndarray:
    import tensorflow as tf

    # ƒë·∫£m b·∫£o model ƒë√£ c√≥ input/output graph
    _ = model.predict(img_array, verbose=0)

    if layer_name is None:
        layer_name = _find_last_conv_layer_name(model)
    if layer_name is None:
        raise ValueError("Kh√¥ng t√¨m th·∫•y Conv2D layer ƒë·ªÉ t·∫°o Grad-CAM")

    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)
    heatmap = tf.maximum(heatmap, 0)
    heatmap = heatmap / (tf.reduce_max(heatmap) + 1e-8)
    return heatmap.numpy()


def overlay_heatmap_on_image(img_pil: Image.Image, heatmap: np.ndarray, alpha: float = 0.45) -> Image.Image:
    base = img_pil.convert("RGB")
    w, h = base.size

    heat = Image.fromarray(np.uint8(heatmap * 255)).resize((w, h), resample=Image.BILINEAR)
    heat_arr = np.array(heat, dtype=np.float32) / 255.0

    cmap = cm.get_cmap("jet")
    colored = cmap(heat_arr)[:, :, :3]
    colored_img = Image.fromarray(np.uint8(colored * 255)).convert("RGB")

    return Image.blend(base, colored_img, alpha=alpha)


def card(title: str, body: str) -> None:
    st.markdown(
        f"""
        <div style="border-radius:16px;padding:16px 18px;background:rgba(255,255,255,0.06);border:1px solid rgba(255,255,255,0.12)">
          <div style="font-size:18px;font-weight:700;margin-bottom:6px">{title}</div>
          <div style="color:rgba(255,255,255,0.85);line-height:1.6">{body}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def page_home() -> None:
    st.header("Trang ch·ªß")
    st.subheader("Gi·ªõi thi·ªáu t·ªïng quan")

    card(
        "M·ª•c ti√™u",
        "X√¢y d·ª±ng h·ªá th·ªëng ph√¢n lo·∫°i b·ªánh l√° l√∫a d·ª±a tr√™n ·∫£nh. Pipeline b√°m s√°t theo b√†i: EDA ‚Üí ti·ªÅn x·ª≠ l√Ω/augmentation ‚Üí hu·∫•n luy·ªán m√¥ h√¨nh ‚Üí ƒë√°nh gi√° ‚Üí d·ª± ƒëo√°n ·∫£nh ƒë·∫ßu v√†o.",
    )

    df = load_dataframe()

    c1, c2, c3 = st.columns(3)
    c1.metric("S·ªë ·∫£nh (train.csv)", f"{len(df):,}")
    c2.metric("S·ªë gi·ªëng l√∫a", f"{df['variety'].nunique():,}")
    c3.metric("S·ªë lo·∫°i b·ªánh", f"{df['label_vi'].nunique():,}")

    st.markdown("---")

    st.subheader("S∆° ƒë·ªì trang")
    st.markdown(
        """
- **Ph√¢n t√≠ch d·ªØ li·ªáu**: bi·ªÉu ƒë·ªì 2D/3D t∆∞∆°ng t√°c (Plotly)
- **ƒê√°nh gi√° m√¥ h√¨nh**: confusion matrix, classification report
- **D·ª± ƒëo√°n ·∫£nh**: upload ·∫£nh v√† d·ª± ƒëo√°n b·ªánh (model `.keras`)
        """
    )


def page_eda() -> None:
    st.header("Ph√¢n t√≠ch d·ªØ li·ªáu (EDA)")
    df = load_dataframe()

    st.subheader("Ph√¢n b·ªë s·ªë l∆∞·ª£ng ·∫£nh theo lo·∫°i b·ªánh (2D)")
    counts = df["label_vi"].value_counts().reset_index()
    counts.columns = ["Lo·∫°i b·ªánh", "S·ªë l∆∞·ª£ng"]
    fig_bar = px.bar(
        counts,
        x="Lo·∫°i b·ªánh",
        y="S·ªë l∆∞·ª£ng",
        title="Ph√¢n b·ªë c√°c lo·∫°i b·ªánh tr√™n l√∫a",
    )
    fig_bar.update_layout(xaxis_tickangle=-35, height=520)
    st.plotly_chart(fig_bar, use_container_width=True)

    st.subheader("T·ªâ l·ªá ph√¢n b·ªë b·ªánh (2D - Pie)")
    fig_pie = px.pie(counts, names="Lo·∫°i b·ªánh", values="S·ªë l∆∞·ª£ng", title="T·ªâ l·ªá ph√¢n b·ªë c√°c lo·∫°i b·ªánh")
    fig_pie.update_layout(height=520)
    st.plotly_chart(fig_pie, use_container_width=True)

    st.subheader("Ph√¢n b·ªë tu·ªïi l√∫a theo b·ªánh (2D - Boxplot)")
    fig_box = px.box(df, x="label_vi", y="age", points="outliers", title="Ph√¢n b·ªë tu·ªïi c√¢y l√∫a theo t·ª´ng lo·∫°i b·ªánh")
    fig_box.update_layout(xaxis_tickangle=-35, height=560)
    st.plotly_chart(fig_box, use_container_width=True)

    st.subheader("Bi·ªÉu ƒë·ªì 3D t∆∞∆°ng t√°c: S·ªë l∆∞·ª£ng m·∫´u theo (Gi·ªëng l√∫a, Lo·∫°i b·ªánh)")
    agg = df.groupby(["variety", "label_vi"]).size().reset_index(name="count")
    fig_3d = px.scatter_3d(
        agg,
        x="variety",
        y="label_vi",
        z="count",
        color="label_vi",
        size="count",
        title="3D: Variety √ó Label ‚Üí Count",
    )
    fig_3d.update_layout(height=700)
    st.plotly_chart(fig_3d, use_container_width=True)

    with st.expander("Xem d·ªØ li·ªáu m·∫´u"):
        st.dataframe(df.head(50), use_container_width=True)

def page_evaluation() -> None:
    st.header("ƒê√°nh gi√° m√¥ h√¨nh")
 
    df = load_dataframe()
    st.caption("Trang n√†y ch·ªâ so s√°nh 3 m√¥ h√¨nh ch√≠nh theo b√†i (c√πng validation).")
 
    st.subheader("So s√°nh 3 m√¥ h√¨nh (c√πng validation)")
    models = discover_keras_models()
 
    wanted = {
        "monster_cnn_best.keras",
        "efnet_b1_best.keras",
        "efnetv2_v2s_best.keras",
    }
    selected_models = []
    for m in models:
        if os.path.basename(m).lower() in wanted:
            selected_models.append(m)
 
    # Fallback n·∫øu kh√¥ng discover ƒë∆∞·ª£c
    if not selected_models:
        selected_models = [
            "monster_cnn_best.keras",
            "efnet_b1_best.keras",
            "efnetv2_v2s_best.keras",
        ]

    img_size = (224, 224)
    batch_size = 32

    cbtn1, cbtn2 = st.columns([1, 2])
    with cbtn1:
        if st.button("Clear cache", use_container_width=True):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.rerun()

    run_compare = st.button("Ch·∫°y so s√°nh", use_container_width=True)
    if run_compare:
        with st.spinner("ƒêang chu·∫©n b·ªã validation v√† ƒë√°nh gi√° 3 model..."):
            from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess
            from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as effv2_preprocess
            import traceback
 
            train_df, val_df = split_train_val(df, test_size=0.2, random_state=42)
 
            def make_generator_for_model(model_path: str):
                name = os.path.basename(model_path).lower()
                current_img_size = (224, 224)
                if "efficientnetb1" in name or "efnet_b1" in name:
                    current_img_size = (240, 240)
                    train_gen = ImageDataGenerator(preprocessing_function=eff_preprocess)
                    val_gen = ImageDataGenerator(preprocessing_function=eff_preprocess)
                elif "efficientnetv2" in name or "efnetv2" in name:
                    train_gen = ImageDataGenerator(preprocessing_function=effv2_preprocess)
                    val_gen = ImageDataGenerator(preprocessing_function=effv2_preprocess)
                else:
                    train_gen = ImageDataGenerator(rescale=1.0 / 255)
                    val_gen = ImageDataGenerator(rescale=1.0 / 255)
                make = build_image_generators(
                    img_size=current_img_size,
                    batch_size=batch_size,
                    train_datagen=train_gen,
                    val_datagen=val_gen,
                )
                return make(train_df, val_df)[1]
 
            results = []
            error_traces = []
            for mp in selected_models:
                resolved_mp = _resolve_model_path(str(ROOT_DIR / mp)) or _resolve_model_path(mp)
                if resolved_mp is None:
                    continue
                try:
                    model = load_tf_model(resolved_mp, model_mtime=os.path.getmtime(resolved_mp))
                except Exception as e:
                    error_traces.append(
                        {
                            "model": os.path.basename(resolved_mp),
                            "stage": "load",
                            "trace": traceback.format_exc(),
                        }
                    )
                    results.append(
                        {
                            "M√¥ h√¨nh": os.path.basename(resolved_mp),
                            "Val loss": None,
                            "Val accuracy": None,
                            "Ghi ch√∫": f"Kh√¥ng load ƒë∆∞·ª£c model: {type(e).__name__}: {e}",
                        }
                    )
                    continue
 
                val_generator = make_generator_for_model(resolved_mp)
                val_generator.reset()
                try:
                    loss, acc = model.evaluate(val_generator, verbose=0)
                    results.append(
                        {
                            "M√¥ h√¨nh": os.path.basename(resolved_mp),
                            "Val loss": float(loss),
                            "Val accuracy": float(acc),
                            "Ghi ch√∫": "",
                        }
                    )
                except Exception as e:
                    error_traces.append(
                        {
                            "model": os.path.basename(resolved_mp),
                            "stage": "evaluate",
                            "trace": traceback.format_exc(),
                        }
                    )
                    results.append(
                        {
                            "M√¥ h√¨nh": os.path.basename(resolved_mp),
                            "Val loss": None,
                            "Val accuracy": None,
                            "Ghi ch√∫": f"Evaluate l·ªói: {type(e).__name__}: {e}",
                        }
                    )
 
        if results:
            res_df = pd.DataFrame(results)
            res_df = res_df.sort_values("Val accuracy", ascending=False, na_position="last")
            c1, c2 = st.columns([1, 1])
            with c1:
                st.dataframe(res_df, use_container_width=True)
            with c2:
                chart_df = res_df.dropna(subset=["Val accuracy"])
                fig_cmp = px.bar(chart_df, x="M√¥ h√¨nh", y="Val accuracy", title="So s√°nh Val Accuracy")
                fig_cmp.update_layout(height=420)
                st.plotly_chart(fig_cmp, use_container_width=True)
        else:
            st.warning("Kh√¥ng c√≥ model h·ª£p l·ªá ƒë·ªÉ so s√°nh.")

        if "error_traces" in locals() and error_traces:
            with st.expander("Chi ti·∫øt l·ªói (traceback)"):
                for it in error_traces:
                    st.markdown(f"**{it['model']}** ‚Äî `{it['stage']}`")
                    st.code(it["trace"], language="text")


def page_predict() -> None:
    st.header("D·ª± ƒëo√°n b·ªánh t·ª´ ·∫£nh")
    st.caption("Upload ·∫£nh l√° l√∫a ƒë·ªÉ model d·ª± ƒëo√°n lo·∫°i b·ªánh (b√°m s√°t ph·∫ßn upload & predict trong notebook).")

    model_path = model_picker("Model d√πng ƒë·ªÉ d·ª± ƒëo√°n")

    if not model_path:
        st.info("B·∫°n ch∆∞a nh·∫≠p ƒë∆∞·ªùng d·∫´n model. N·∫øu ch∆∞a c√≥ model, h√£y train trong c√°c file `src/model_*.py`. ")
        return

    resolved = _resolve_model_path(model_path)
    if resolved is None:
        st.error("Kh√¥ng t√¨m th·∫•y file model. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        return

    img_size = (224, 224)
    batch_size = 32

    with st.spinner("ƒêang load model..."):
        try:
            model = load_tf_model(resolved)
        except Exception as e:
            st.error(
                "Kh√¥ng load ƒë∆∞·ª£c model. Model c√≥ th·ªÉ ƒë∆∞·ª£c train sai input (v√≠ d·ª• ·∫£nh grayscale 1 k√™nh) ho·∫∑c kh√°c k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o."
            )
            st.code(str(e))
            return

    class_indices = get_class_indices(img_size=img_size, batch_size=batch_size)
    idx_to_class = {v: k for k, v in class_indices.items()}

    uploaded = st.file_uploader("Ch·ªçn ·∫£nh (jpg/png)", type=["jpg", "jpeg", "png"])

    if uploaded is None:
        st.stop()

    img = Image.open(uploaded)
    st.image(img, caption="·∫¢nh b·∫°n ƒë√£ upload", use_container_width=True)

    with st.spinner("ƒêang d·ª± ƒëo√°n..."):
        df_prob = predict_pil_image(model, img, img_size=img_size, idx_to_class=idx_to_class, model_path=resolved)

    top = df_prob.iloc[0]
    st.success(f"D·ª± ƒëo√°n: {top['Lo·∫°i b·ªánh']} ‚Äî ƒê·ªô tin c·∫≠y: {top['X√°c su·∫•t (%)']:.2f}%")

    st.subheader("B·∫£ng x√°c su·∫•t")
    st.dataframe(df_prob, use_container_width=True)

    st.subheader("Bi·ªÉu ƒë·ªì x√°c su·∫•t (2D)")
    fig = px.bar(df_prob.head(10), x="Lo·∫°i b·ªánh", y="X√°c su·∫•t (%)", title="Top x√°c su·∫•t d·ª± ƒëo√°n")
    fig.update_layout(xaxis_tickangle=-35, height=520)
    st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    show_cam = st.toggle("Hi·ªÉn th·ªã Grad-CAM (Monster CNN)", value=False)
    if show_cam:
        st.subheader("Gi·∫£i th√≠ch d·ª± ƒëo√°n (Grad-CAM)")
        st.caption(f"Heatmap cho model: {os.path.basename(resolved)}")

        try:
            img_resized = img.convert("RGB").resize(img_size)
            
            # X·ª≠ l√Ω Preprocessing t∆∞∆°ng ·ª©ng cho t·ª´ng lo·∫°i model ƒë·ªÉ Grad-CAM ch√≠nh x√°c
            name = os.path.basename(resolved).lower()
            arr = np.array(img_resized, dtype=np.float32)
            if "efnet" in name:
                from tensorflow.keras.applications.efficientnet import preprocess_input
                arr = preprocess_input(arr)
            else:
                arr = arr / 255.0
            
            arr = np.expand_dims(arr, axis=0)

            # T·ª± ƒë·ªông t√¨m l·ªõp Convolutional cu·ªëi c√πng c·ªßa t·ª´ng model
            layer_name = _find_last_conv_layer_name(model)
            
            if layer_name:
                heatmap = grad_cam_heatmap(model, arr, layer_name=layer_name)
                overlay = overlay_heatmap_on_image(img_resized, heatmap, alpha=0.45)
                st.image(overlay, caption=f"V√πng t·∫≠p trung c·ªßa m√¥ h√¨nh (Layer: {layer_name})", use_container_width=True)
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y l·ªõp Conv2D ph√π h·ª£p ƒë·ªÉ t·∫°o Grad-CAM.")
        except Exception as e:
            st.error(f"L·ªói t·∫°o Grad-CAM: {e}")


def main() -> None:
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon="üåæ",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    st.markdown(
        """
        <style>
          .stApp {
            background: radial-gradient(1200px 600px at 10% 10%, rgba(80, 180, 255, 0.18), transparent 60%),
                        radial-gradient(1000px 500px at 90% 20%, rgba(0, 255, 170, 0.12), transparent 55%),
                        linear-gradient(180deg, #0B1220 0%, #070B14 100%);
            color: #E6EDF3;
          }
          h1, h2, h3, h4, h5, h6 { color: #E6EDF3; }
          [data-testid="stSidebar"] {
            background: rgba(255,255,255,0.04);
            border-right: 1px solid rgba(255,255,255,0.10);
          }
          [data-testid="stMetric"] {
            background: rgba(255,255,255,0.06);
            border: 1px solid rgba(255,255,255,0.12);
            padding: 12px 14px;
            border-radius: 14px;
          }
          .block-container { padding-top: 1.5rem; }
          .stButton>button {
            border-radius: 12px;
            border: 1px solid rgba(255,255,255,0.18);
            background: rgba(255,255,255,0.08);
          }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title(APP_TITLE)

    menu = st.sidebar.radio(
        "ƒêi·ªÅu h∆∞·ªõng",
        ["Trang ch·ªß", "Ph√¢n t√≠ch d·ªØ li·ªáu", "ƒê√°nh gi√° m√¥ h√¨nh", "D·ª± ƒëo√°n ·∫£nh"],
        index=0,
    )

    st.sidebar.markdown("---")
    st.sidebar.caption("B√°m s√°t theo notebook: EDA ‚Üí preprocess ‚Üí model ‚Üí evaluation ‚Üí predict")

    if menu == "Trang ch·ªß":
        page_home()
    elif menu == "Ph√¢n t√≠ch d·ªØ li·ªáu":
        page_eda()
    elif menu == "ƒê√°nh gi√° m√¥ h√¨nh":
        page_evaluation()
    else:
        page_predict()


if __name__ == "__main__":
    main()
